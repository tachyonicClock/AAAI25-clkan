{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Europe Wind Datasets\n",
    "\n",
    "1. The Europe wind dataset is available from https://www.uni-kassel.de/eecs/ies/downloads\n",
    "  on request.\n",
    "2. Once obtained please extract the data and place it in your `TORCH_DATA_DIR` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:27:54.213376Z",
     "iopub.status.busy": "2024-08-18T02:27:54.212860Z",
     "iopub.status.idle": "2024-08-18T02:27:54.547433Z",
     "shell.execute_reply": "2024-08-18T02:27:54.547006Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from os import environ\n",
    "import h5py\n",
    "\n",
    "\n",
    "data_directory = Path(environ.get(\"TORCH_DATA_DIR\")).expanduser().resolve()\n",
    "eurowind_data = data_directory / \"EuropeWindFarm/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:27:54.549291Z",
     "iopub.status.busy": "2024-08-18T02:27:54.549156Z",
     "iopub.status.idle": "2024-08-18T02:27:54.797685Z",
     "shell.execute_reply": "2024-08-18T02:27:54.797264Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://developer.nvidia.com/blog/three-approaches-to-encoding-time-information-as-features-for-ml-models/\n",
    "from sklego.preprocessing import RepeatingBasisFunction\n",
    "\n",
    "\n",
    "def rbf_day_of_year(day_of_year: np.ndarray) -> np.ndarray:\n",
    "    df_day_of_year = pd.DataFrame({\"day_of_year\": day_of_year})\n",
    "    rbf_day_of_year = RepeatingBasisFunction(\n",
    "        n_periods=12, input_range=(1, 365), remainder=\"drop\", column=\"day_of_year\"\n",
    "    )\n",
    "    rbf_day_of_year.fit(df_day_of_year)\n",
    "    return rbf_day_of_year.transform(df_day_of_year)\n",
    "\n",
    "\n",
    "def rbf_hour_of_day(hour_of_day: np.ndarray) -> np.ndarray:\n",
    "    df_hour_of_day = pd.DataFrame({\"hour_of_day\": hour_of_day})\n",
    "    rbf_hour_of_day = RepeatingBasisFunction(\n",
    "        n_periods=6, input_range=(0, 23), remainder=\"drop\", column=\"hour_of_day\"\n",
    "    )\n",
    "    rbf_hour_of_day.fit(df_hour_of_day)\n",
    "    return rbf_hour_of_day.transform(df_hour_of_day)\n",
    "\n",
    "\n",
    "def rbf_forecasting_hour(forecasting_hour: np.ndarray) -> np.ndarray:\n",
    "    df_forecasting_hour = pd.DataFrame({\"forecasting_hour\": forecasting_hour})\n",
    "    rbf_forecasting_hour = RepeatingBasisFunction(\n",
    "        n_periods=6, input_range=(0, 48), remainder=\"drop\", column=\"forecasting_hour\"\n",
    "    )\n",
    "    rbf_forecasting_hour.fit(df_forecasting_hour)\n",
    "    return rbf_forecasting_hour.transform(df_forecasting_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:27:54.799592Z",
     "iopub.status.busy": "2024-08-18T02:27:54.799416Z",
     "iopub.status.idle": "2024-08-18T02:27:54.803632Z",
     "shell.execute_reply": "2024-08-18T02:27:54.803319Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_wf_df(df: pd.DataFrame, windfarm_id: int, windfarm_count: int):\n",
    "    dates = np.array(df[\"Time\"].map(lambda x: np.datetime64(x, \"h\")))\n",
    "    year = dates.astype(\"datetime64[Y]\").astype(int) + 1970\n",
    "    month = dates.astype(\"datetime64[M]\").astype(int) % 12 + 1\n",
    "    day_of_month = (\n",
    "        dates.astype(\"datetime64[D]\") - dates.astype(\"datetime64[M]\") + 1\n",
    "    ).astype(int)\n",
    "    hour_of_day = dates.astype(\"datetime64[h]\").astype(int) % 24\n",
    "    day_of_year = np.array(\n",
    "        [\n",
    "            datetime.datetime(1, month[i], day_of_month[i]).timetuple().tm_yday\n",
    "            for i in range(len(dates))\n",
    "        ]\n",
    "    )\n",
    "    timestamp = dates.astype(\"datetime64[h]\").astype(int)\n",
    "\n",
    "    rbf_day_of_year_ = rbf_day_of_year(day_of_year)\n",
    "    for i in range(12):\n",
    "        df[f\"rbf_day_of_year_{i:02d}\"] = rbf_day_of_year_[:, i]\n",
    "\n",
    "    rbf_hour_of_day_ = rbf_hour_of_day(hour_of_day)\n",
    "    for i in range(6):\n",
    "        df[f\"rbf_hour_of_day_{i:02d}\"] = rbf_hour_of_day_[:, i]\n",
    "\n",
    "    rbf_forecasting_time = rbf_forecasting_hour(np.array(df[\"ForecastingTime\"]))\n",
    "    for i in range(6):\n",
    "        df[f\"rbf_forecasting_time_{i:02d}\"] = rbf_forecasting_time[:, i]\n",
    "\n",
    "    # Add dummy variables for windfarm_id\n",
    "    for i in range(windfarm_count):\n",
    "        df[f\"windfarm_id_{i:02d}\"] = 0\n",
    "\n",
    "    df[f\"windfarm_id_{windfarm_id:02d}\"] = 1\n",
    "    df[\"year\"] = year\n",
    "    df.drop(columns=[\"Time\", \"ForecastingTime\"], inplace=True)\n",
    "    df[\"timestamp\"] = timestamp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:27:54.804910Z",
     "iopub.status.busy": "2024-08-18T02:27:54.804789Z",
     "iopub.status.idle": "2024-08-18T02:27:57.254016Z",
     "shell.execute_reply": "2024-08-18T02:27:57.253582Z"
    }
   },
   "outputs": [],
   "source": [
    "windfarm_count = 46\n",
    "wf_df = []\n",
    "for windfarm_id in range(1, windfarm_count):\n",
    "    csv = eurowind_data / f\"wf{windfarm_id:d}.csv\"\n",
    "    wf_df.append(process_wf_df(pd.read_csv(csv), windfarm_id - 1, windfarm_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:27:57.255627Z",
     "iopub.status.busy": "2024-08-18T02:27:57.255501Z",
     "iopub.status.idle": "2024-08-18T02:27:57.282739Z",
     "shell.execute_reply": "2024-08-18T02:27:57.282396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine all the datasets into one by chronological order\n",
    "df_full = pd.concat(wf_df[:3]).sort_values(by=\"timestamp\")\n",
    "df_full = df_full.drop(columns=[\"timestamp\"])\n",
    "for i, feature in enumerate(df_full.columns):\n",
    "    print(i, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:27:57.301032Z",
     "iopub.status.busy": "2024-08-18T02:27:57.300882Z",
     "iopub.status.idle": "2024-08-18T02:27:58.011029Z",
     "shell.execute_reply": "2024-08-18T02:27:58.010647Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "x_dataset = Tensor(df_full.drop(columns=[\"PowerGeneration\"]).values)\n",
    "y_dataset = Tensor(df_full[\"PowerGeneration\"].values)\n",
    "\n",
    "# Standardize the features\n",
    "x_dataset = (x_dataset - x_dataset.mean(dim=0)) / x_dataset.std(dim=0)\n",
    "y_dataset = (y_dataset - y_dataset.mean(dim=0)) / y_dataset.std(dim=0)\n",
    "x_dataset = x_dataset.numpy().astype(np.float32)\n",
    "y_dataset = y_dataset.numpy().astype(np.float32)\n",
    "\n",
    "print(\"x_dataset.shape:\", x_dataset.shape)\n",
    "print(\"y_dataset.shape:\", y_dataset.shape)\n",
    "# Count NaNs in the dataset\n",
    "print(\"Number of NaNs in x_dataset:\", np.isnan(x_dataset).sum())\n",
    "print(\"Number of NaNs in y_dataset:\", np.isnan(y_dataset).sum())\n",
    "\n",
    "x_dataset = np.nan_to_num(x_dataset, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:27:58.012540Z",
     "iopub.status.busy": "2024-08-18T02:27:58.012418Z",
     "iopub.status.idle": "2024-08-18T02:27:58.077160Z",
     "shell.execute_reply": "2024-08-18T02:27:58.076643Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_filename = data_directory / \"eurowind.hdf5\"\n",
    "\n",
    "with h5py.File(hdf5_filename, \"w\") as f:\n",
    "    f.create_dataset(\"x_features\", data=x_dataset, dtype=\"float32\", compression=\"gzip\")\n",
    "    f.create_dataset(\n",
    "        \"y_targets\", data=y_dataset.reshape(-1, 1), dtype=\"float32\", compression=\"gzip\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
