{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare River Radar Dataset\n",
    "\n",
    "1. Download `rain_radar.tar.gz (58MB)` from https://datasets.cms.waikato.ac.nz/taiao/river_radar_2015_2018/.\n",
    "2. Once obtained please place the archive in your `TORCH_DATA_DIR` directory. **DO NOT EXTRACT THE ARCHIVE.**\n",
    "3. Run this notebook to generate `riverradar.hdf5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:30:52.535698Z",
     "iopub.status.busy": "2024-08-18T02:30:52.534928Z",
     "iopub.status.idle": "2024-08-18T02:30:55.904272Z",
     "shell.execute_reply": "2024-08-18T02:30:55.903960Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tarfile import TarFile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from os import environ\n",
    "from sklego.preprocessing import RepeatingBasisFunction\n",
    "import h5py\n",
    "\n",
    "data_directory = Path(environ.get(\"TORCH_DATA_DIR\", \".\")).expanduser().resolve()\n",
    "riverradar_data = data_directory / \"river_radar.tar.gz\"\n",
    "with TarFile.open(riverradar_data) as tar:\n",
    "    df = pd.read_csv(tar.extractfile(\"merged_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Time Features\n",
    "Neural networks require timestamps to be embedded into real numbers. We do\n",
    "this using repeating basis functions as described in (1).\n",
    "\n",
    "- (1) https://developer.nvidia.com/blog/three-approaches-to-encoding-time-information-as-features-for-ml-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:30:55.905975Z",
     "iopub.status.busy": "2024-08-18T02:30:55.905871Z",
     "iopub.status.idle": "2024-08-18T02:30:56.071463Z",
     "shell.execute_reply": "2024-08-18T02:30:56.071029Z"
    }
   },
   "outputs": [],
   "source": [
    "datetimes = pd.to_datetime(df[\"datetimeUTC\"])\n",
    "year_offset = datetimes.apply(lambda datetime: datetime.year - 2015)\n",
    "day_of_year = datetimes.apply(lambda datetime: datetime.dayofyear)\n",
    "hour_of_day = datetimes.apply(lambda datetime: datetime.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:30:56.073119Z",
     "iopub.status.busy": "2024-08-18T02:30:56.072988Z",
     "iopub.status.idle": "2024-08-18T02:30:56.239232Z",
     "shell.execute_reply": "2024-08-18T02:30:56.238807Z"
    }
   },
   "outputs": [],
   "source": [
    "def rbf_day_of_year(day_of_year: np.ndarray) -> np.ndarray:\n",
    "    df_day_of_year = pd.DataFrame({\"day_of_year\": day_of_year})\n",
    "    rbf_day_of_year = RepeatingBasisFunction(\n",
    "        n_periods=12, input_range=(1, 365), remainder=\"drop\", column=\"day_of_year\"\n",
    "    )\n",
    "    rbf_day_of_year.fit(df_day_of_year)\n",
    "    return rbf_day_of_year.transform(df_day_of_year)\n",
    "\n",
    "\n",
    "def rbf_hour_of_day(hour_of_day: np.ndarray) -> np.ndarray:\n",
    "    df_hour_of_day = pd.DataFrame({\"hour_of_day\": hour_of_day})\n",
    "    rbf_hour_of_day = RepeatingBasisFunction(\n",
    "        n_periods=6, input_range=(0, 23), remainder=\"drop\", column=\"hour_of_day\"\n",
    "    )\n",
    "    rbf_hour_of_day.fit(df_hour_of_day)\n",
    "    return rbf_hour_of_day.transform(df_hour_of_day)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    day_embedding = torch.tensor(rbf_day_of_year(day_of_year))\n",
    "    hour_embedding = torch.tensor(rbf_hour_of_day(hour_of_day))\n",
    "    year_embedding = torch.nn.functional.one_hot(\n",
    "        torch.tensor(year_offset), num_classes=4\n",
    "    )\n",
    "    time_features = torch.cat([day_embedding, hour_embedding, year_embedding], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:30:56.241047Z",
     "iopub.status.busy": "2024-08-18T02:30:56.240868Z",
     "iopub.status.idle": "2024-08-18T02:30:56.245925Z",
     "shell.execute_reply": "2024-08-18T02:30:56.245432Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, feature in enumerate(df.columns):\n",
    "    print(i, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Features\n",
    " * Columns 1-140 contains the gridded radar reflectance taken at 10x14 grid, taken at sea level\n",
    " * Columns 141-280 contains the gridded radar reflectance taken at 10x14 grid, taken at 2000m above sea level\n",
    " * Columns 281-420 contains the gridded radar reflectance taken at 10x14 grid, taken at 4000m above sea level\n",
    " * Columns 421-422 contains the river stage levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:30:56.266836Z",
     "iopub.status.busy": "2024-08-18T02:30:56.266666Z",
     "iopub.status.idle": "2024-08-18T02:30:56.399712Z",
     "shell.execute_reply": "2024-08-18T02:30:56.399341Z"
    }
   },
   "outputs": [],
   "source": [
    "features = torch.tensor(df[df.columns[1:421]].to_numpy())\n",
    "targets = torch.tensor(df[df.columns[421:]].to_numpy())\n",
    "print(features.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Features and Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:30:56.401041Z",
     "iopub.status.busy": "2024-08-18T02:30:56.400892Z",
     "iopub.status.idle": "2024-08-18T02:30:56.852706Z",
     "shell.execute_reply": "2024-08-18T02:30:56.852415Z"
    }
   },
   "outputs": [],
   "source": [
    "x_dataset = torch.cat([features, time_features], dim=1)\n",
    "y_dataset = targets\n",
    "\n",
    "# Standardize the features\n",
    "x_dataset = (x_dataset - x_dataset.mean(dim=0)) / x_dataset.std(dim=0)\n",
    "y_dataset = (y_dataset - y_dataset.mean(dim=0)) / y_dataset.std(dim=0)\n",
    "\n",
    "print(\"x_dataset.shape:\", x_dataset.shape)\n",
    "print(\"y_dataset.shape:\", y_dataset.shape)\n",
    "# Count NaNs in the dataset\n",
    "print(\"Number of NaNs in x_dataset:\", np.isnan(x_dataset).sum())\n",
    "print(\"Number of NaNs in y_dataset:\", np.isnan(y_dataset).sum())\n",
    "\n",
    "x_dataset = x_dataset.numpy().astype(np.float32)\n",
    "x_dataset = np.nan_to_num(x_dataset, nan=0.0)\n",
    "y_dataset = y_dataset.numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:30:56.854580Z",
     "iopub.status.busy": "2024-08-18T02:30:56.854451Z",
     "iopub.status.idle": "2024-08-18T02:30:57.657013Z",
     "shell.execute_reply": "2024-08-18T02:30:57.656763Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_filename = data_directory / \"riverradar.hdf5\"\n",
    "\n",
    "with h5py.File(hdf5_filename, \"w\") as f:\n",
    "    f.create_dataset(\"x_features\", data=x_dataset, dtype=\"float32\", compression=\"gzip\")\n",
    "    f.create_dataset(\"y_targets\", data=y_dataset, dtype=\"float32\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
